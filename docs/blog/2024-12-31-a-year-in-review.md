---
title: "2024: A Year in Review for GenAI"
description: "A look back at the year in GenAI"
date: 2024-12-31
image: /img/blog/images/2024-12-31-year-in-review.png
---
# A Year in Review

On the last day of 2024, it is a good time to reflect on the changes. What a year it has been.

## Open Models

It was just prior to NeurIPS 2023 in December 2023 when Mistral famously dropped their quiet torrent of the 8x7B model. In many ways, I felt like that was a bellweather moment for open source AI. This was the "as good as 3.5 Turbo at home!" moment.

For context, neither of those models ranks **in the top 100** of the LMSys Arena Leaderboard.

Instead, the accidental Llama 2 followed by Mistral's models, Llama 3, and then open source models like Qwen 2.5, Deepseek v2/2.5/3 led us to this auspicious moment.

![Code Leaderboard](/img/blog/images/2024-12-31-code-leaderboard.png)

Developers here at [Kamiwaza](https://kamiwaza.ai) have access to every tool but we've had a number of occasions where Qwen2.5-Coder-32B would figure something out in code where both Claude 3.5 Sonnet and GPT-4o, and sometimes even o1, would fail.

I found Qwen particularly delightful, partially because the Qwen team released many sizes of the model. This led me to re-test speculative decoding on [Llama.cpp](https://github.com/ggerganov/llama.cpp); and when I was seeing a 55% performance boost from a 77% accept rate of tokens generated by the 7B drafting for the 32B, ggerganov brushed off the speculative code and got it working back in `llama-server` which was an amazing outcome and so personally useful. (Although I'm not shy about leveraging foundational models, I have dedicated hardware and do generate millions of tokens per day minimum.)

So


Meta followed with Llama 3 and then 3.1 in July, with the 405B model being a true challenger to foundational proprietary models like GPT-4.

In the latter part of the year, two Chinese models hit the scene. First, the Qwen team from Alibaba released Qwen 2.5; then DeepSeek released DeepSeek v3.

## OpenAI and Anthropic retain a lead

On the other hand, I'd be remiss if I didn't mention that OpenAI and Anthropic held onto a lead. Anthropic's Claude 3.5 Sonnet is simply amazing at code and in general, for what used to be the most obsequious of models it has a great tone and can be downright funny. OpenAI's GPT-4o remained excellent, but was never as good as Claude 3.5 Sonnet in coding tasks. However, OpenAI released o1, and the o1 models continue to be astoundingly good. They're simply slow. One can see a clear connection though.


