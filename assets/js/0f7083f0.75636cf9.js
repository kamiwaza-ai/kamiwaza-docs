"use strict";(self.webpackChunkkamiwaza_docs=self.webpackChunkkamiwaza_docs||[]).push([[5097],{10644:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>h,frontMatter:()=>a,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"services/ingestion/README","title":"Ingestion Service","description":"Overview","source":"@site/sdk/services/ingestion/README.md","sourceDirName":"services/ingestion","slug":"/services/ingestion/","permalink":"/sdk/services/ingestion/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"sdk","previous":{"title":"Embedding Service","permalink":"/sdk/services/embedding/"},"next":{"title":"Lab Service","permalink":"/sdk/services/lab/"}}');var r=i(74848),t=i(28453);const a={sidebar_position:1},l="Ingestion Service",o={},c=[{value:"Overview",id:"overview",level:2},{value:"Key Features",id:"key-features",level:2},{value:"Data Ingestion",id:"data-ingestion",level:2},{value:"Available Methods",id:"available-methods",level:3},{value:"Integration with Other Services",id:"integration-with-other-services",level:2},{value:"Error Handling",id:"error-handling",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Performance Considerations",id:"performance-considerations",level:2},{value:"Data Formats",id:"data-formats",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"ingestion-service",children:"Ingestion Service"})}),"\n",(0,r.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,r.jsxs)(n.p,{children:["The Ingestion Service (",(0,r.jsx)(n.code,{children:"IngestionService"}),") provides comprehensive data ingestion functionality for the Kamiwaza AI Platform. Located in ",(0,r.jsx)(n.code,{children:"kamiwaza_client/services/ingestion.py"}),", this service handles data ingestion workflows, dataset processing, and document handling with embedding capabilities."]}),"\n",(0,r.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Data Ingestion"}),"\n",(0,r.jsx)(n.li,{children:"Dataset Catalog Integration"}),"\n",(0,r.jsx)(n.li,{children:"Document Processing"}),"\n",(0,r.jsx)(n.li,{children:"Embedding Generation"}),"\n",(0,r.jsx)(n.li,{children:"Batch Processing Support"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"data-ingestion",children:"Data Ingestion"}),"\n",(0,r.jsx)(n.h3,{id:"available-methods",children:"Available Methods"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"ingest(data: Union[str, List[str], Dict[str, Any]], **kwargs) -> IngestionResponse"}),": Ingest data"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"ingest_dataset(dataset: Dataset, **kwargs) -> DatasetIngestionResponse"}),": Ingest dataset to catalog"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:'initialize_embedder(provider: str = "default", **kwargs) -> None'}),": Initialize embedding provider"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"process_documents(documents: List[Document], **kwargs) -> ProcessingResponse"}),": Process documents"]}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# Simple data ingestion\nresponse = client.ingestion.ingest(\n    data="Sample text data",\n    chunk_size=512\n)\n\n# Dataset ingestion\nresponse = client.ingestion.ingest_dataset(\n    dataset=dataset_obj,\n    embedding_config={\n        "provider": "huggingface",\n        "model": "sentence-transformers/all-mpnet-base-v2"\n    }\n)\n\n# Initialize embedder\nclient.ingestion.initialize_embedder(\n    provider="huggingface",\n    model_name="sentence-transformers/all-mpnet-base-v2"\n)\n\n# Process documents\nresponse = client.ingestion.process_documents(\n    documents=[\n        Document(text="doc1", metadata={"source": "file1"}),\n        Document(text="doc2", metadata={"source": "file2"})\n    ],\n    chunk_size=512,\n    overlap=50\n)\n'})}),"\n",(0,r.jsx)(n.h2,{id:"integration-with-other-services",children:"Integration with Other Services"}),"\n",(0,r.jsx)(n.p,{children:"The Ingestion Service works in conjunction with:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Embedding Service","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"For generating embeddings of ingested text"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["VectorDB Service","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"For storing processed vectors"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Catalog Service","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"For dataset management"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Retrieval Service","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"For accessing processed documents"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,r.jsx)(n.p,{children:"The service includes built-in error handling for common scenarios:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'try:\n    response = client.ingestion.ingest(data)\nexcept EmbeddingError:\n    print("Embedding generation failed")\nexcept VectorDBError:\n    print("Vector storage failed")\nexcept ProcessingError as e:\n    print(f"Document processing failed: {e}")\nexcept APIError as e:\n    print(f"Operation failed: {e}")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"Initialize embedder before ingestion"}),"\n",(0,r.jsx)(n.li,{children:"Use appropriate chunk sizes"}),"\n",(0,r.jsx)(n.li,{children:"Include relevant metadata"}),"\n",(0,r.jsx)(n.li,{children:"Process documents in batches"}),"\n",(0,r.jsx)(n.li,{children:"Monitor ingestion progress"}),"\n",(0,r.jsx)(n.li,{children:"Handle errors appropriately"}),"\n",(0,r.jsx)(n.li,{children:"Clean up failed ingestions"}),"\n",(0,r.jsx)(n.li,{children:"Validate data before ingestion"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Batch size affects processing speed"}),"\n",(0,r.jsx)(n.li,{children:"Embedding generation time"}),"\n",(0,r.jsx)(n.li,{children:"Vector database insertion overhead"}),"\n",(0,r.jsx)(n.li,{children:"Memory usage during processing"}),"\n",(0,r.jsx)(n.li,{children:"Network bandwidth for large datasets"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"data-formats",children:"Data Formats"}),"\n",(0,r.jsx)(n.p,{children:"The service supports various input formats:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Raw Text","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Single strings"}),"\n",(0,r.jsx)(n.li,{children:"Lists of strings"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Structured Data","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"JSON objects"}),"\n",(0,r.jsx)(n.li,{children:"Dictionaries"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Documents","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Custom Document objects"}),"\n",(0,r.jsx)(n.li,{children:"Metadata support"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["Datasets","\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Catalog integration"}),"\n",(0,r.jsx)(n.li,{children:"Batch processing"}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>l});var s=i(96540);const r={},t=s.createContext(r);function a(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);