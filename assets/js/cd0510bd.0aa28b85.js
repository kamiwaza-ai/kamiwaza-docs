"use strict";(self.webpackChunkkamiwaza_docs=self.webpackChunkkamiwaza_docs||[]).push([[2778],{10515:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>t,metadata:()=>r,toc:()=>o});const r=JSON.parse('{"id":"services/embedding/README","title":"Embedding Service","description":"Overview","source":"@site/sdk/services/embedding/README.md","sourceDirName":"services/embedding","slug":"/services/embedding/","permalink":"/sdk/services/embedding/","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"sdk","previous":{"title":"Cluster Service","permalink":"/sdk/services/cluster/"},"next":{"title":"Ingestion Service","permalink":"/sdk/services/ingestion/"}}');var d=i(74848),s=i(28453);const t={sidebar_position:1},l="Embedding Service",c={},o=[{value:"Overview",id:"overview",level:2},{value:"Key Features",id:"key-features",level:2},{value:"Text Processing",id:"text-processing",level:2},{value:"Available Methods",id:"available-methods",level:3},{value:"Model Management",id:"model-management",level:2},{value:"Available Methods",id:"available-methods-1",level:3},{value:"Error Handling",id:"error-handling",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Provider Configuration",id:"provider-configuration",level:2}];function a(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,d.jsxs)(d.Fragment,{children:[(0,d.jsx)(n.header,{children:(0,d.jsx)(n.h1,{id:"embedding-service",children:"Embedding Service"})}),"\n",(0,d.jsx)(n.h2,{id:"overview",children:"Overview"}),"\n",(0,d.jsxs)(n.p,{children:["The Embedding Service (",(0,d.jsx)(n.code,{children:"EmbeddingService"}),") provides comprehensive text embedding functionality for the Kamiwaza AI Platform. Located in ",(0,d.jsx)(n.code,{children:"kamiwaza_client/services/embedding.py"}),", this service handles text chunking, embedding generation, and provider management."]}),"\n",(0,d.jsx)(n.h2,{id:"key-features",children:"Key Features"}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsx)(n.li,{children:"Text Chunking"}),"\n",(0,d.jsx)(n.li,{children:"Embedding Generation"}),"\n",(0,d.jsx)(n.li,{children:"Multiple Provider Support"}),"\n",(0,d.jsx)(n.li,{children:"Batch Processing"}),"\n",(0,d.jsx)(n.li,{children:"Model Management"}),"\n",(0,d.jsx)(n.li,{children:"Provider Initialization"}),"\n"]}),"\n",(0,d.jsx)(n.h2,{id:"text-processing",children:"Text Processing"}),"\n",(0,d.jsx)(n.h3,{id:"available-methods",children:"Available Methods"}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"chunk_text(text: str, chunk_size: int = 512) -> List[str]"}),": Split text into chunks"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"embed_chunks(chunks: List[str]) -> List[List[float]]"}),": Generate embeddings for chunks"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"create_embedding(text: str) -> List[float]"}),": Create embedding for text"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"get_embedding(embedding_id: UUID) -> Embedding"}),": Get existing embedding"]}),"\n"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-python",children:'# Split text into chunks\nchunks = client.embedding.chunk_text(\n    text="Long document text...",\n    chunk_size=512\n)\n\n# Generate embeddings for chunks\nembeddings = client.embedding.embed_chunks(chunks)\n\n# Create single embedding\nembedding = client.embedding.create_embedding("Sample text")\n\n# Retrieve existing embedding\nstored_embedding = client.embedding.get_embedding(embedding_id)\n'})}),"\n",(0,d.jsx)(n.h2,{id:"model-management",children:"Model Management"}),"\n",(0,d.jsx)(n.h3,{id:"available-methods-1",children:"Available Methods"}),"\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"reset_model()"}),": Reset embedding model"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"call(texts: List[str]) -> List[List[float]]"}),": Generate batch embeddings"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"initialize_provider(provider: str, **kwargs)"}),": Initialize embedding provider"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"HuggingFaceEmbedding(model_name: str)"}),": Create HuggingFace embedder"]}),"\n",(0,d.jsxs)(n.li,{children:[(0,d.jsx)(n.code,{children:"get_providers() -> List[str]"}),": List available providers"]}),"\n"]}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-python",children:'# Reset model\nclient.embedding.reset_model()\n\n# Batch embedding generation\nembeddings = client.embedding.call(["text1", "text2", "text3"])\n\n# Initialize provider\nclient.embedding.initialize_provider(\n    provider="huggingface",\n    model_name="sentence-transformers/all-mpnet-base-v2"\n)\n\n# Create HuggingFace embedder\nembedder = client.embedding.HuggingFaceEmbedding(\n    model_name="sentence-transformers/all-mpnet-base-v2"\n)\n\n# List available providers\nproviders = client.embedding.get_providers()\n'})}),"\n",(0,d.jsx)(n.h2,{id:"error-handling",children:"Error Handling"}),"\n",(0,d.jsx)(n.p,{children:"The service includes built-in error handling for common scenarios:"}),"\n",(0,d.jsx)(n.pre,{children:(0,d.jsx)(n.code,{className:"language-python",children:'try:\n    embedding = client.embedding.create_embedding("text")\nexcept ModelNotFoundError:\n    print("Embedding model not found")\nexcept ProviderError as e:\n    print(f"Provider error: {e}")\nexcept APIError as e:\n    print(f"Operation failed: {e}")\n'})}),"\n",(0,d.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,d.jsxs)(n.ol,{children:["\n",(0,d.jsx)(n.li,{children:"Choose appropriate chunk sizes for your use case"}),"\n",(0,d.jsx)(n.li,{children:"Use batch processing for better performance"}),"\n",(0,d.jsx)(n.li,{children:"Initialize providers with appropriate models"}),"\n",(0,d.jsx)(n.li,{children:"Handle model resets properly"}),"\n",(0,d.jsx)(n.li,{children:"Monitor embedding quality"}),"\n",(0,d.jsx)(n.li,{children:"Use appropriate error handling"}),"\n",(0,d.jsx)(n.li,{children:"Consider memory usage for large batches"}),"\n",(0,d.jsx)(n.li,{children:"Cache frequently used embeddings"}),"\n"]}),"\n",(0,d.jsx)(n.h2,{id:"provider-configuration",children:"Provider Configuration"}),"\n",(0,d.jsx)(n.p,{children:"The service supports multiple embedding providers:"}),"\n",(0,d.jsxs)(n.ol,{children:["\n",(0,d.jsxs)(n.li,{children:["HuggingFace","\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsx)(n.li,{children:"Supports various model architectures"}),"\n",(0,d.jsx)(n.li,{children:"Customizable model selection"}),"\n",(0,d.jsx)(n.li,{children:"Local and remote inference"}),"\n"]}),"\n"]}),"\n",(0,d.jsxs)(n.li,{children:["Custom Providers","\n",(0,d.jsxs)(n.ul,{children:["\n",(0,d.jsx)(n.li,{children:"Extensible provider interface"}),"\n",(0,d.jsx)(n.li,{children:"Custom model integration"}),"\n",(0,d.jsx)(n.li,{children:"Provider-specific configurations"}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,d.jsx)(n,{...e,children:(0,d.jsx)(a,{...e})}):a(e)}},28453:(e,n,i)=>{i.d(n,{R:()=>t,x:()=>l});var r=i(96540);const d={},s=r.createContext(d);function t(e){const n=r.useContext(s);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(d):e.components||d:t(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);